**计算之魂** Aug 14 1-22 
1. 硅谷中心的计算机博物馆有介绍，最早的计算机可追溯到2000年前的**中国算盘**。其实希腊更早出现过算盘，  
  但它不是计算机，为什么呢？主要原因是，希腊算盘只是用来辅助计数的存储设备，不具备控制计算的功能，  
  计算还是靠人。中国算盘靠珠算口诀来控制操作，不管输入什么，用一套口诀就能得到结果。从算盘的设计和  
  使用上可看出构成计算机的三要素：*计算单元、存储单元、指令序列*。
2. 最早的**机械计算机**由法国数学家帕斯卡在1642年发明，可做加减运算。比算盘的先进之处是，用齿轮等机械  
  传动装置代替口诀。能进行微积分运算机器的是英国巴贝奇，但受限于机械制造的复杂度，差分机的发展进入  
  死胡同。带领大家走出死胡同的是布尔、香农和楚泽。
   1. 布尔通过二进制将算术和简单的数理逻辑统一起来，并提供了**布尔代数**。
   2. 楚泽通过时间证明了使用布尔代数可以实现任何十进制运算，实现更复杂的逻辑。
   3. 香农从理论上指出任何逻辑控制和计算都和**开关电路**等价，奠定数字电路设计的基础。
3. 计算机的本质是机械运动，这就引出计算机的数学模型——**图灵机**。ps：《三体》提到用人模拟计算机的运行  
  也揭露了这一本质。图灵机的数学模型：
   1. 有一条无限长的被分成一个个格子的纸带，每个格子里记录这符号。
   2. 有一个读写头，在纸带上移动，停在哪里就可以改变哪里的符号。
   3. 有一套规则表，根据当前状态和读写头所指格子中的符号或数字，人查表（口诀）进行操作，更新状态。
   4. 记录状态的地方叫做寄存器，状态的数量有限。计算完成就进入停机状态。
   
   1946年出现的电子计算机ENIAC就是一种实用的图灵机。
4. 图灵是超越时代的人，他提出了计算机的边界。计算机能解决什么问题呢？它只能解决数学问题，更精确点是  
  有明确答案的数学问题，再精确点是可在有限步骤计算出来的数学问题。现在的人工智能也没超越该边界。

**计算之魂** Aug 15 23-44
1. 高德纳，算法分析鼻祖，最年轻的图领奖得主。著有《基本算法》、《计算机程序设计艺术》等名著，为了  
  方便写书他开发出了排版工具TeX（后被人做成更方便用的LaTex）成为学术排版规范。
2. 很多人对大数缺乏敏感度，比如这个问题，N数量级达到万以上时O(NlogN)和O(N^2)的差距有多大。
3. 给你一个数组，请你找到其中一个区间，使内部和最大。作者给出几种方法，跳过复杂度为O(N^2)以上的：
   1. 分而治之O(NlogN)：将数组从中间切分为两块，分别计算它们总和最大的区间。有3种可能：一是左边  
   更大，二是右边更大，三是二者合并更大。至于如何求每块的和最大的区间，递归即可。
   2. 正反两遍扫描法O(N)：首先考虑一种特殊情况，所有数不大于0，那最大的数就是结果。想象从左到右  
   遍历数组的每个元素并累加，会有一个峰值，其右让和变小——是区间要抛弃的。同样地可以逆向扫描  
   得到左边界。但是注意，可能左边界在右边界右边，要单独考虑。
   
   ps：感觉用滑动窗口或者动态规划更香，同样线性时间复杂度，但只扫描一遍就够了。滑动窗口简洁：  
   左右边界l,r初始化为0，r++算[l, r]累加和s，result=max(result, s)。当s<0时，l和r都自增。循环这一过程。  
   不过也不否认，左右两遍扫描还是有启发性的，只是不比滑动窗口更具一般性和自然智慧。

**计算之魂** Aug 16 44-56
1. 归并排序算法之所以能达到O(NlogN)的时间复杂度，是因为它利用了X>Y，Y>Z则X>Z这个大小的传递性，  
  这是在两个子有序的子序列合并时用的，避免了每个数都跟所有其他数作比较。
2. Python中默认用的Tim排序的时间复杂度也是O(NlogN)，但是效率更高。它先利用插入排序将各段变有序，  
  再再局部有序的基础上归并即可。
3. 一个有意思的思考题：25人赛跑，只有5个跑道（每轮比赛只能有5人参加），问至少几轮能角逐出前三名。
  假设每个人发挥稳定，且没有计时器可用。  
  ps：可以先平分为五组，进行5轮比赛，让每组中排第三名的人再比赛1轮，其中第一名可能是第三名，其余  
  四人及其后的都淘汰（第一名是其所在组的第三，顶多是全局第三）。于是只有11人留下。  
  此时，让5组中每组的第二名比赛1轮，则至少可以淘汰4或5人（下图中斜体〇参加比赛，黑体表示前三）：
   1. 上一轮第一名组内第二在本轮拿了第一名，则可以淘汰后4名。有7人留下。

      小组第一  〇   _〇  〇  〇  〇_  
      小组第二  _〇_   <s>〇  〇  〇  〇  </s>     
      小组第三  〇
   
      后面该第二名跟其余组第一比赛1轮，a.如果继续得第一，则前两名定了，剩下5人再赛1轮争夺第三名。

      小组第一  **〇**   _〇  〇  〇  〇_  
      小组第二  **〇**  
      小组第三  _〇_  
      b.否则，淘汰掉那个小组第三和最后两名，剩余4人比最后一轮即可。  
    a和b都是**9**轮比赛得到前三名。
   2. 上一轮第一名的组内第二在本轮没能拿第一名，则可以淘汰后5人。有6人留下。

      小组第一  〇   _〇  〇  〇  〇_  
      小组第二 _〇_   <s>〇  〇  〇  〇  </s>     
      小组第三  ~~〇~~  
     再赛1轮：  
     a. 如果小组第二在这轮是第一名，则这轮第二名是最终的第三名。  
     b. 如果小组第二在这轮是第二名，则他就是第三，前两名是曾他快的俩（不分名次）。  
     c. 如果小组第二在这轮是第三/四/五名，则淘汰，剩余5人。剩下的5人还需要赛1轮才知道前三。  
    小结：情况a需要比赛**8**轮，b需要**8**轮（若想知道前三的名词还得加赛1轮），c需要**9**轮。
   
    总结i和ii，需要**9**轮才能确定前三。

**计算之魂** Aug 17 60-80
1. 昨天的25人赛跑问题想复杂了，只需要5+1+1=7轮就能知道前三名了：  
   前5轮让每个小组内排好了序，第6轮让组内第一比，必能得到第一名，他所在组的前三都可能进整体前三：  
   小组第一  **〇**   〇  〇  〇  〇  
   小组第二  〇  
   小组第三  〇    
   重要的点来了——第6轮的最后两名绝无机会进前三，**他俩无需参赛**，于是再来一轮比赛即可确定：  
   小组第一  **〇**   〇  〇  ~~〇  〇~~  
   小组第二  〇  
   小组第三  〇    
2. **递归思想**特别重要，它是计算机思维的核心，我们要学会这种思考方式，以理解递推难以归纳的问题。
   1. 汉诺塔问题：有三根柱子A、B、T，A串若干上面小下面大的圆盘，怎样让它们移动到B，要求只能一次  
   移动一个盘，且全程不能有大盘压小盘的情况出现。  
   利用递归思想，用h(n, A, B, T)表示原问题，它可以分为子问题：
      1. 先h(n-1, A, T, B)
      2. 再将A剩的一个盘移到B
      3. 再h(n-1, T, B, A)。
      
       由此我们还能得到问题规模递推式：H(n)=2*H(n-1)-1，子问题层层嵌套，递推难解，但递归容易。
   2. 爬楼梯问题：一次只能爬1或2阶，要爬上n阶楼梯有多少种方法？  
     f(n) = f(n-1) + f(n-2)。没错，就是斐波那契数列，递归思想的核心就是找到通用模式将问题由大化小。
   3. 八皇后问题：8*8的棋盘中放八个皇后，且任意两个皇后都不能在同一行、同一列或同一斜线上。  
   不用递归的话就更难了，八皇后有92种放法，暴力解的话有8!约四万多组合。用递归，可以假设7个皇后  
   已经摆好，要摆最后一个；如果最后一个放哪里都不行，说明前7个皇后位置不可取。
   4. 二叉树问题，这个不用多说，用递归遍历极其简洁。

**计算之魂** Aug 18 80-97
1. 我们对树研究最多的是二叉树，一个原因是它简单，可以利用计算机二进制的优势。还有一个重要原因是，  
   二叉树等价跟任何多叉树等价。任何一个多叉树上的节点可以有子节点和兄弟节点，那我们就可以让多叉树  
  做下变形，第一个子节点N变为左树，其余子节点变为N的右树。且这样得到的二叉树还能能原样变回去。
2. 递归的特点是层层嵌套，递归其实是嵌套的特例（自己套自己）。嵌套本身也是计算机思维的特点，函数、  
  模块化、抽象都能看出这一点。嵌套可能让问题变得很复杂，比如自然语言的语法分析，句子由动词短语和  
  名词短语构成，名词短语本身也可由多个名词短语构成。人类很容易自底向上将短语构成句子，然而想要使  
  计算机能自顶向下分析句子语法，就很复杂，不分析上下文的话，时间复杂度是O(N^3)；分析上下文则变成  
  NP hard的问题，经过简化可达到O(N^6)，这在工程上就难以实现了。基于概率的NLP算法成为更优选择。


**计算之魂** Aug 19 98-114
1. 万物皆编码，人、城市、街道的名字是编码，IP地址、化学符号、数学方程也是编码。人类的编码跟计算机  
  不同，后者编码就是为了区分，这有时候会让我们陷入茫然，有时则会给我们有益的启发。相关问题：
   1. A要给B打工7天，要求B支付一根金条（每天1/7）根。B想只在金条上切两刀，怎么切能保证B给A报酬  
   日结，且不超不欠？
   2. 有64瓶药，其中仅1瓶有毒，最少用几只小鼠可试出哪瓶有毒？要求，只能做一次实验，一只小鼠可以  
   吃多瓶药。（用信息论可以很快得出答案）
2. 计算机中的浮点数用了科学计数法，其目的是能表示更大范围的数据，但代价是其精度损耗。IEEE754-2008  
  标准采用64位二进制编码，正负号占1位，范围占11位（-1024~1023），精度占52位。最大能表示10<sup>308</sup>，  
  最小能表示10<sup>-308</sup>。但是过大的数的表示是很稀疏的，如10<sup>307</sup>-10<sup>308</sup>之间有9*10<sup>307</sup>个数，计算机中只有10<sup>17</sup>  
  种编码，即多个数会被近似表示成一个数字。且数字的精度跟范围不可兼得。这种粗细结合很有启发性：  
   1. 用俩一样的玻璃球测试它们从几楼（已知在1~100内）扔下会刚好摔碎。怎样测才能让实验次数最少？


**计算之魂** Aug 21 115-133
1. 非线性编码：编码跟实际值不是线性关系，如取对数编码，使较小的数分辨率更高，语音常用该方式。
2. 增量编码：第一个数取中间值，其余的，仅取原数减去第一个数得到差值进行编码。也能实现省空间。   
  这在4K视频（120帧/秒）编码中经常用到，利用帧间差异小的特性，空间占用可以缩小到千分之几！
3. 哈夫曼编码，本质是给出现概率大的数据以短编码，概率小的数用长编码，使得整体空间占用更小。  
   其实莫尔斯编码也利用了这个，从信息论的角度看，这两个操作都会使平均码长往信息熵靠近。
4. 矩阵的编码常用到三元组表示非0值的元素信息——(行,列,值)，矩阵的加减乘除也在此编码上进行的话，  
  就需要增加索引，方便获取值。

**计算之魂** Aug 22 134-147
1. 计算机解决现实生活中的问题一般分两步，先将实际问题变成信息处理（分类、组织、查找、重组）问题，  
   再通过算法将这些信息处理问题变成计算问题。
2. 文字识别、下围棋等很多被称作人工智能的问题的本质是分类识别。以文字识别为例，算法要做的是将文字  
  分到合适的模式（集合）中，那些帮助分类的差异可认为是多维度的变量。
3. 二叉决策树可以解决所有分类逻辑（二叉树可等效为多叉树），操作简单，且能高效表示大量事物。
4. 如果一个集合的特征不明确，则决策树不适用。如果其元素可枚举，那可以用哈希表来划定集合的边界。  
  比如，屏蔽色情网站就可以用这种思想。具体有三种实现：
   1. 直接存整个哈希表，需要消耗很大的空间。
   2. 布隆过滤器，但是会存在假阳性问题。
   3. 二分决策和哈希表结合，前者用来分离出我们关注的元素。

**计算之魂** Aug 23 147-153
1. 计算机中有很多东西的诞生是权衡的结果，B树也是如此。不同的树中，多叉树查询效率高，但是比二叉树  
  更占空间。B树每个节点有若干值决定子树值的范围，靠将子节点数限制在d~2d之间平衡时间和空间效率。
2. B+树在B树的基础上做了两处改进：第一是非叶子节点只保留键；第二是有一个指针将叶子节点串联起来。  
  这种结构更干净，索引部分占用空间更小，另外还方便范围查询。
3. 数据库常用B+树结构，就是利用了上述优点。我们可以想象要构建一个字典，用二叉树的话，可能会很深；  
  用26叉树的话，则会浪费很多空间（每个节点都要预留26个子节点的位置）。
4. B*树在B+树的基础上，增加了非叶子节点的兄弟之间的指针。另外优化了分/合节点的条件，提高空间效率。


**计算之魂** Aug 26 153-163
1. **卡特兰数**在很多问题中出现，比如：
   1. 已知一个满二叉树（文中指任意节点的子节点都不是1个）有N个叶子节点，这样的树有多少种？C(N)
   2. 将一个凸N边形通过顶点连线划分为N-2种不重叠的三角形，有多少种划分方法？C(N-2)
   3. 要让含N个字符的序列组成字符串，相邻两个可以合并为新的字符串，问有多少种合并方法？C(N-1)  
     比如abcd有五种合并方法：((ab)c)d、(a(bc))d、(ab)(cd)、a((bc)d)、a(b(cd))
   
   这些问题都是用递归的思想更易解答。字符串合并问题，原始问题记作f(N)，则k字符合并后剩余问题就是  
   f(N-k)，k可以取任意小于N的正数，问题一分为二后二者相互独立，故f(N) = ∑f(k)*f(N-k).
2. 卡特兰数是N的指数函数，这反映的是信息组织方式的多样。


**计算之魂** Aug 27 164-180
1. 对图论的研究可以追溯到三个世纪前的七桥问题，欧拉经过研究发现问题无解。他把问题抽象为节点和边，  
  要一笔无重复地走过所有边并回到起点，则每个节点都必须连奇数条边，不然总会有一条边走不到。
2. 将网页看成节点，之间的超链接看成边，它们也构成一个图。如何下载所有网页？这不是简单的图的遍历  
  问题，而是复杂工程问题（网络爬虫），需要考虑下面问题：
   1. 图是有向的，跟无向图比它的连通性可能很差，很可能不是强联通的，而无法从某节点出发遍历完图。
   2. 节点不可枚举，这问题没有完美的解决方案，一般思路是动态发现所有网页，将其加入集合。
   3. 节点和链接是动态变化的，在遍历的过程中会标记网页是否遍历过，可能存在这种问题——刚被标记过    
    的网页更新了，添加了到网页的新链接，则新的网页会被漏掉。也存在找不到网页的问题。
   4. 体量大，Google有百亿个网页，一台服务器得花三年左右的时间才能下载完。为此我们可用多台服务器  
     并行下载，那如何保证不会出现几台服务器同时下载一个网页而有些总不被访问到的情况？
   5. 并行工作如何协调也是问题，服务器A下载了一个网页，怎样避免其他服务器重复下载它呢？容易想到  
    A通知其他服务器，但是一千台服务器、一百亿网页，要发出的消息数达到十万亿！另一个思路是构建  
    两级（或三级）网络爬虫系统，一个服务器作为协调者告诉每台服务器下载哪些网页。但它很容易成为  
   瓶颈。好吧，我们可以划分任务，比如每个服务器下载不同IP范围的网页，但可能有数据倾斜问题……
   6. 网站对爬虫的限速。

**计算之魂** Aug 28 180-203
1. Dijkstra算法，用于计算一个节点到其他节点的最短路径。思路：
   1. 先算出起点S到其他所有节点的距离，把这些节点放到集合V1中.
   2. 找到V1直接可达的节点，算出S到那些节点的最短距离，将这批新的节点和V1都放到新集合V2中。 
   3. 用类似的方法得到跟V2相邻的节点的最短路径，形成新的集合V3……直至S到E的最短路径被找到。
2. 最大流问题的解决步骤：切割起、终与它们间的节点之间的连线，可以得到最小切割流量，它就是瓶颈，即  
  可以达到的最大流量。然后找到流量不饱和（流量还可增加）的路径，增广路径。这个只要存在流量小于  
  最小切割流量的路径，那就一定能找到增广路径，直到路径流量达到最大流。
3. 除了网络流量分配，还有司机乘客配对、婚恋配对等二分图也可以用这个方法解决。


**计算之魂** Aug 29 207-218
1. **分治思想**对于算法来说不是简单的线性分割，考虑N个数冒泡排序，计算量k*N<sup>2</sup>，如果平分两组分别排序，  
  计算量为2k(N/2)<sup>2</sup>即k\*N<sup>2</sup>/2，计算量减半。按照这个思路不断分割下去，计算量就可能达到数量级的差距。
2. 分治思想的应用除了归并排序还有很多，复杂度为O(NlogN)的算法大部分（除堆排序）都用到它。
3. 如何从组内有序的N组序列中选出前K大的元素？可以利用组内有序，将每组最大值放大根堆，每次弹出的  
  元素属于哪个组就将那个组的元素（每组要有个指针）放入堆。循环此过程K次即可。

**计算之魂** Aug 30 219-231
1. 分治思想并不简单，几个面试：
   1. 如何以O(N)的时间复杂度找到一个数组的中位数（参考下题思路三）。
   2. 在一个数组里找到前K大的数。
      1. 思路一，排序找前K，时间复杂度是O(NlogN)，没分儿……
      2. 思路二，构建容量为K+1的小根堆，先添加K个元素，遍历剩余的，逐个加入堆再弹出一个，剩的K  
      个就是答案。时间复杂度是O(NlogK)，显然K越小这种方式效率越高。
      3. 思路三，选枢值，将剩余元素与之比较以分成右大左小两个区。枢值的位置在左(N-K)就将左边界赋  
      为枢值，在右K就将右边界赋为枢值位置。在新的左右边界内选择新的枢值循环上述过程。  
      平均时间复杂度是O(N)——假设每次都能抛弃掉固定的比例，则计算量等比下降，故收敛到N！
   3. 一个超大数组分布在1000台机器上（一台放不下），如何找到数组的中位数。  
    也是O(N)的时间复杂度——随机选一个枢值，让每台机器统计大于和小于该值的元素数分别累加得到  
   m、n，m>n则下次选更大的，否则下次选更小的枢值循环上述过程。
2. 分治可以化繁为简的奥秘就是舍弃不可能，难点是不容易直观的想到。看下面一题：
   1. 找两个已排序数组的中位数。提示：时间复杂度**O(logN)**

**计算之魂** Aug 31 231-247
1. 继续学习分治思想，主要是在并行计算领域的应用，一是MapReduce，二是深度学习。
2. Google的PageRank计算本身是矩阵相乘问题，矩阵达到行列都有上亿元素的规模。根据矩阵乘法分配律，  
  [A]·[B]，可以将A按行分成n个矩阵，将B按列切分为n个矩阵，第i个A的子矩阵跟第j个B的子矩阵的乘积就是  
  最终结果的第(i,j)个块。公式让分治变得简单，还可以进一步，将A子矩阵按列、B子矩阵按行再拆相乘。
3. 相比于矩阵乘法，机器学习训练算法就更难了，它计算量大不好拆分，因为训练的各部分可能是紧耦合的。  
  一个有N个特征的模型，机器学习即通过数据训练得到这N个特征所对应的N个参数（深度学习模型里参数就  
  是有向图中边的权重）。训练样本有K个，这里K>>N，一台服务器无法装这么多数据。考虑模型的大小：
   1. 一台服务器能容纳模型，那只切分数据即可。
   2. 一台服务器无法容纳模型，那数据跟模型都得切分。如果知道特征f<sub>i</sub>跟数据d<sub>i</sub>是否有关联，则可以这样分  
      f<sub>1</sub> f<sub>2</sub> d<sub>1</sub>，f<sub>3</sub> d<sub>2</sub>，f<sub>2</sub> f<sub>3</sub> d<sub>3</sub>……  
4. Google大脑是并行深度学习领域的伟大工程，它采用神经网络这种通用性好、对称性好的算法，模块之间的  
  关联不那么紧密，可以在精度损失不大的条件下解耦合。Google大脑团队的创举就是解耦，将神经网络切分  
  只后，每一块的训练只跟周围八个块有关，规模有效分解，虽然计算量大了一个数量级，但它是线性增加。

**计算之魂** Sep 3 248-265
1. 权衡时空是计算机存储中的艺术。
2. 如何快速数32或64位二进制数中1的个数？暴力方法逐位数就不说了。
   1. 循环计算`x&(x-1)`直至等于零，循环次数就是答案。该方法易于用硬件实现，代码短，但不太直观。
   2. 用空间换时间，把8bit能表示的256个数字有多少个1存起来，将所给数分为8bit的段查表即可。当然可以  
    把16或32bit能表示的数对应的1数都存起来，我们用k表示bit数，那空间占用会达到2<sup>k</sup>，时间收益跟k只  
   是线性关系。
3. 如何从一台服务器上1TB数据量的语料库统计出现频率最高的100万个单词二元组（内存资源有限）？
   1. 不可行的几个思路：
      1. 直接用二维大数组，x和y分别表示构成二元组的第一、二个单词的序号，考虑单词至少有20万个，  
      数组大小会达到400亿*4字节=160G内存。
      2. 将上述二维数组用压缩矩阵存储，不可行的原因是该问题不是稀疏矩阵（自然语言齐普夫定律）。
      3. 哈希表+硬盘存储，问题是慢，会有三个数量级的差距。
      4. 用容量100万的堆，只留出现频数最高的。思路错误，这个队列会剔除高频但出现隔远的二元组。
   2. 可行的思路：
      1. 随机抽样，如0.1%即1GB数据，统计其中二元组次数，只保留前1000万高频的二元组。假设它包含  
      前100万高频的二元组，最后遍历1TB数据统计在这1000万中的即可。利用近似 随机性决定精度。
      2. 分治算法：
         1. 将文本分为N份，D<sub>1</sub>,D<sub>2</sub>,D<sub>3</sub>,...,D<sub>N</sub>，比如N为1000，用哈希表存放<x,y>及其频数，其中x、y  
         仍是二元组中第一、二个词的编号。D<sub>i</sub>的频数用C<sub>i</sub>表示，按照x和y编号大小排序后暂存磁盘。
         2. 归并排序，得到按x、y排序的<x,y,C>。
         3. 最后用前面说的并行找中值的方法，找到前100万多的单词二元组。


**计算之魂** Sep 4 265-279
1. 计算机存储层次，老生常谈了，CPU和硬盘之间的速度鸿沟导致L1、L2、L3缓存的产生。为什么L2比L1慢呢？  
  一是跟CPU的距离远，时钟频率按3.3GHz算，电流每周期的速度只有9cm。二是容量大，速度跟平方根成反比。
2. 实际上随着云计算的发展，云存储成了位于硬盘之外的新存储层次，它是更慢的、跨服务器的。
3. 前面说的 保存k位二进制表示的所有2^k个数中都含有几个1，这个问题在考虑缓存时，k取8而非32是更高效的，  
因为一般L1的容量只有数十到上百k，L2只有几百k，k大了就容易不命中缓存。
4. 能在写代码时考虑到利用硬盘的特性，才有成为四级工程师的能力。其特性——顺序访问快，随机访问特慢。
5. **索引**让顺序存储的数据的检索（随机访问，范围访问）更加快捷。其本质是将内容映射为地址，用地址访问。

**计算之魂** Sep 5 280-286
1. 并行是提高计算机性能的重要手段，处理器流水线和一些软件系统设计都体现了这一点。
2. 流水线在逻辑上是串行的，在物理上并行。即，机器码级别的操作逐个串行执行，一个指令被变成多条指令  
  进行串行执行。多条指令——取指、译码、执行、访存和写回间是并行的。这样就可以在一个时钟周期执行  
  5条指令，效率提升5倍。
3. 理想情况下流水线级数有多大就提速多少倍，但特殊情况是分支逻辑，在不知道if成立和否的情况下无法预知  
  下一个指令是谁，这里就涉及等待或预取以及预测惩罚了。
4. 摩尔定律有两个分水岭：第一、2000年左右，提高处理器效率的手段不再是主频、位数，而是多核。  
  第二、2016年左右，行业不再单纯追求处理器的绝对性能，而是追求单位能耗锁能提供的计算量。


**计算之魂** Sep 8 286-296
1. GFS用于解决存储信息的问题。Google俩创始人在下载网页构建搜索引擎时发现，按照网页原先的存储方式  
  存储，一个网页放一个文件中，数据访问效率太低，时间多花在读写数据的准备阶段。于是发明了BigFile，  
  它在逻辑上包含所有网页，物理上以64MB为一个单元（chunk）。这极大提高了海量小文件的读/写效率，  
  存在的问题是想要取某一个小文件的代价比较大。GFS跟BigFile比，chunk只是逻辑上的，对用户透明。
2. GFS服务器有主、从两种，应用程序从主服务器获取文件路径信息，再据此找到从服务器访问文件。这样就能  
  避免主服务器传输大量文件而成为瓶颈。另外文件有备份，读快写慢。
3. MapReduce过程（还以统计最多的百万二元组为例）：Map时用1000台服务器，编号1~1000，i号服务器只  
  统计在词汇表中排i/1000~(i+1)/1000位的x构成的<x,y>二元组。Reduce时，汇总1000台服务器的数据。
4. 这里可以改进一下，服务器只统计自己关心的1/1000的数据，采用本地存储，不管其他99.9%。
5. 如果数据量极大，一台服务器无法放下所有二元组，那就做两次Map，一次Reduce。第一次Map还是各服务器  
  并行统计；然后按二元组的序号进行归并排序（多机器）。



**计算之魂** Sep 9 297-305
1. 计算解决问题的本质就是**把问题分解成独立的状态或过程**，实际上计算机硬件的设计也是一样。
2. 看一个捕鼠问题：彼此相连的五个格子里有一个老鼠，它每天都往相邻格子（可左可右）移动。你只能一天打  
   开一个盒子（完了还要合上），请设计一个能找到老鼠的策略。
    <table>
    <tr><td></td> <td></td> <td>鼠</td> <td></td> <td></td> <td></td> </tr>
    </table>
    看起来问题很复杂，也难也到一个稳妥的方案，因为状态有点多。正确的思路是抽象，将第1、3、5个格看作  
    一种状态S，2、4看作另一种状态T。  
   
   1. 假设小鼠第一天是T状态，那我们可以打开第2个，有就抓到，没有则说明它在4。第二天打开第3个，有就  
     抓住了，没有则说明它在第5个，第3天开第4个，一定有。
   2. 如果上面三天都没抓住，则说明一开始假设错了，当时鼠的状态是S。好，那三天了状态肯定变成T，重复  
     上述步骤就一定能抓到它。
3. 在自然语言处理领域也经常把数据分为状态，比如N元文法模型，有些词组合极少出现，以频率作概率误差会  
   很大。可以将词映射到词性，基于词性分析词组词频，还能简化模型提高计算效率。


**计算之魂** Sep 10 305-319
1. 等价性可以用于将状态抽象出来。如，怎么实现俩变量值的交换，要求不使用临时变量。这涉及的就是状态的  
  叠加，可以用异或操作，也可以用加法。加法操作过程：
   1. 初始值 x： 2，y： 3
   2. x+y赋值给x，x：5，y：3
   3. x-y赋值给y，x：5，y：2
   4. x-y赋值给x，x：3，y：2
   
   上述x、y各状态在变化，但是存储的信息是等价的。
2. 在音频处理领域，时域信号常变换到频域处理，可以极为方便地去掉噪声（高频信号）或做其他处理。除此，  
  图片也会做这种等价变换，如像素图转为JPEG格式就是将空间信号变成等价的频率信号，实现压缩。
3. 状态直接存在联系，或者说因果关系。将不同状态看作图的不同节点，实际问题可以大幅简化。比如，有6只  
  老虎要划船过河，3大虎分别有一个孩子，大虎与孩子在同岸时，孩子会被同岸大虎吃掉。船只能装下俩虎，  
  怎样才能让所有老虎都安全过河？  
  Aa Bb Cc ||  
  A Bb Cc || a  
  A B Cc || a b  
  Bb Cc  || Aa  
  b c || Aa B C  
   || Aa Bb Cc  


**计算之魂** Sep 14 320-329
1. 信息指纹：将任何一个对象（二进制信息）映射成的一个随机数。用伪随机数算产生算法，将对象映射为ID。  
  既然是随机，那就有可能存在重复。128位二进制数作信息指纹，产生多少个以后，出现重复的可能性=50%？  
  第k个指纹不重复的概率P<sub>k</sub>=[N(N-1)(N-2)...(N-k+1)]/N<sup>k</sup>.令P<sub>k</sub>=0.5，根据斯特林公式，N很大时  
  k=(1+8Nln2)<sup>1/2</sup>/2，N=2<sup>128</sup>有k≈1.8*10<sup>19</sup>。
  k不大，道理跟存在生日同天的同班同学的可能性问题类似。
2. 今天所说的量子通信不是利用量子纠缠原理，而是利用光子的偏振传递一次性密钥，用一次性密钥加密信息。  
  香农证明了只有一次性加密是无法破解的加密方式，一次性就是靠随机性来保证的。45或135度偏振的光经过  
  水平和垂直光栅，出来的光的偏振方向是水平和竖直的可能性相等，都是50%。发送和接受端先约定两种信息  
  编码方式，一组用垂直的偏振光代表1、0，另一组用45、135度代表1、0。发送端随机交替采用一种方式编码，  
  接收端也不知道到底是哪一种，只能猜，猜对了会得到100%一致，否则有50%一致。再考虑窃听者，光要经过  
  错误放置的光栅，偏振方向无从得知，得到的信息也是75%的一致性，若将该信息转发回接收端，则只有75%  
   的平方即56%和发送端一致，这就能知道信息被偷听了。  
  保证了安全，下面再消除不确定性，确定双方通信的密钥：发送端只需将偏振方向传给接收端，接收端就知道   
  哪些信息对了，哪些错了，将设置对的信息位（密钥）告诉发送端即可。这两个过程都是明文发送的。


**计算之魂** Sep 14 329-337
1. 计算机算法发展可分两阶段，第一阶段是发现复杂度更低的算法。各算法复杂度确定后，进入第二阶段——  
  更好的算法。比如排序算法中的快速排序、AlphaGo博弈算法。AlphaGo算法做了两大改进，a. 纵向简化即引入  
  马尔科夫假设。b. 横向简化，即搜索时的剪枝策略。
2. 上述简化和剪枝有一个小的可能导致找不到最佳策略，但是只要在一定的置信度条件下，它就是可以接受的。
3. 关于如何在特殊情况下进一步优化算法，作者给了一个有难度思考题：  
  我们知道有序数组中找给定数字的复杂度是O(logN)，那再加一个条件——数组符合均匀分布或指数分布，如何  
  进一步优化算法复杂度呢（数据的范围可以在O(1)时间内得到，复杂度O(log(logN)）？

   

**计算之魂** Sep 15 338-347
1. 求最长连续子序列（不同于子串，序列可由不相邻元素组成）。如7,1,3,2,4,5,7,6的最长连续子序列是3,4,5,6。  
  可以采用hash表的方法来做，遍历并记录已形成的连续序列的长度，以序列最大元素作key，长度作value。  
  现在改一下题目，将给定有序子序列改成集合——不考虑顺序，组成连续子序列即可。上述方法改进一下即可。
2. 如何合并区间？区间有交集即可合并为一个更大的。  
  考虑该算法的复杂度，是否存在线性时间复杂度的解法。答案是否定的。最简单的情况下，所有区间都不相交，  
  我们要得到的结果就是排序（按下界）后的结果，排序时间复杂度需要O(NlogN).


**计算之魂** Sep 16 347-367
1. 12个小球中有1个重量与其他不同，只有一个天平，如何只用三次天平找出不同的那个球？  
  如果没有对信息和编码原理的深刻理解，这题等同于很难的智力题。有理论指导即可判断能否解，以及怎么解。  
  这是一个24选1问题，每个都有轻/重两种可能，每次使用天平可以得到1吹特（trit）信息，3<sup>3</sup>=27>24，有解。
2. 如何以O(N)的时间复杂度找出字符串的最长回文子串？  
  Manacher算法，它使用了动态规划——以k+1位置为中心的最长回文子串可由以k为中心的最长回文子串得到，  
  两者的边界关系可以分三种情况，分析清楚了每种情况的回文子串的可扩展性，就能得到解题过程。这里的难点  
  是利用回文和子回文的特性来节省计算。


**计算之魂** Sep 18 完结
1. 从数组中找和为k的子数组。也是典型的动态规划问题，遍历元素时计算前i个元素和S<sub>i</sub>并记录，若S<sub>j</sub>-k存在，那  
  就找到了i+1到j元素就是满足条件的子数组。
2. 本书主要讲了计算机的几大概念——算法复杂度、递归思想、编码、分类组合、图论、分治思想、存储中的时空  
  权衡、流水线和分布式计算、等价性和因果关系、概率算法等。  
  作者对工程师按水平分为五级，将级别的评判标准用对上述概念的理解程度具体化。  
  书中讲了很多硅谷大厂面试题，每题都标了难度星级。有些确实很难，有些作者认为难的题，现在看也并不难，  
  比如作者将动态规划类题目的难度标得高，实际上不少动态规划算法也不难写，这可能有力扣的贡献。
 
















